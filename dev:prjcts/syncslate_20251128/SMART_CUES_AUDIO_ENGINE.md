# SMART CUES éŸ³å£°ã‚¨ãƒ³ã‚¸ãƒ³è¨­è¨ˆ

## ğŸµ éŸ³å£°å†ç”Ÿã®å…¨ä½“ãƒ•ãƒ­ãƒ¼

### 1. ã‚«ã‚¦ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã®åŸºæœ¬æ§‹é€ 

```typescript
/**
 * ãƒ¡ã‚¤ãƒ³ã®ã‚«ã‚¦ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—
 * SMART CUESã‚’è€ƒæ…®ã—ãŸã‚«ã‚¦ãƒ³ãƒˆèª­ã¿ä¸Šã’
 */
async function runCountSequence(
  sequenceDuration: number,
  smartCues: SmartCue[],
  audioContext: AudioContext
): Promise<void> {
  let currentCount = 0;

  while (currentCount <= sequenceDuration) {
    const loopStartTime = audioContext.currentTime;

    // SMART CUEãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    const cue = smartCues.find(c => c.timestamp === currentCount);

    if (cue && cue.audioType !== 'number') {
      // SMART CUEãŒã‚ã‚‹å ´åˆ
      await playCueAudio(cue, audioContext);

      // ã‚«ã‚¹ã‚¿ãƒ éŸ³å£°ã®å ´åˆã€ã‚¹ã‚­ãƒƒãƒ—å‡¦ç†
      if (cue.audioType === 'custom' && cue.customAudioDuration) {
        const skipCount = Math.ceil(cue.customAudioDuration);
        currentCount += skipCount;
      } else {
        // é€šå¸¸ã¯1ç§’å¾…æ©Ÿ
        await waitForNextCount(loopStartTime, audioContext);
        currentCount++;
      }
    } else {
      // é€šå¸¸ã®ã‚«ã‚¦ãƒ³ãƒˆ
      await speakNumber(currentCount, audioContext);
      await waitForNextCount(loopStartTime, audioContext);
      currentCount++;
    }
  }
}

/**
 * æ¬¡ã®ã‚«ã‚¦ãƒ³ãƒˆã¾ã§å¾…æ©Ÿï¼ˆå¿…ãš1ç§’é–“éš”ï¼‰
 */
async function waitForNextCount(
  loopStartTime: number,
  audioContext: AudioContext
): Promise<void> {
  const elapsed = audioContext.currentTime - loopStartTime;
  const waitTime = Math.max(0, 1.0 - elapsed);

  if (waitTime > 0) {
    await sleep(waitTime * 1000);
  }
}

/**
 * ã‚¹ãƒªãƒ¼ãƒ—é–¢æ•°
 */
function sleep(ms: number): Promise<void> {
  return new Promise(resolve => setTimeout(resolve, ms));
}
```

---

## ğŸ”Š éŸ³å£°ã‚¿ã‚¤ãƒ—åˆ¥ã®å†ç”Ÿãƒ­ã‚¸ãƒƒã‚¯

### 1. ãƒ†ã‚­ã‚¹ãƒˆèª­ã¿ä¸Šã’ï¼ˆ0.8ç§’åˆ¶é™ï¼‰

```typescript
/**
 * ãƒ†ã‚­ã‚¹ãƒˆèª­ã¿ä¸Šã’ï¼ˆGemini TTSä½¿ç”¨ï¼‰
 * 0.8ç§’ã§å¼·åˆ¶ã‚¹ãƒˆãƒƒãƒ—
 */
async function speakTextWithLimit(
  text: string,
  audioContext: AudioContext,
  maxDuration: number = 0.8
): Promise<void> {
  // Gemini TTSã§MP3ç”Ÿæˆ
  const audioData = await generateTTS(text);

  // MP3ã‚’AudioBufferã«å¤‰æ›
  const audioBuffer = await audioContext.decodeAudioData(audioData);

  // AudioBufferSourceNodeã§å†ç”Ÿ
  const source = audioContext.createBufferSource();
  source.buffer = audioBuffer;
  source.connect(audioContext.destination);

  const startTime = audioContext.currentTime;
  source.start(startTime);

  // 0.8ç§’å¾Œã«å¼·åˆ¶åœæ­¢
  const stopTime = startTime + maxDuration;
  source.stop(stopTime);

  // åœæ­¢ã¾ã§å¾…æ©Ÿ
  return new Promise(resolve => {
    source.onended = () => resolve();
  });
}

/**
 * Gemini TTSã§MP3ã‚’ç”Ÿæˆ
 */
async function generateTTS(text: string): Promise<ArrayBuffer> {
  const apiKey = import.meta.env.VITE_GEMINI_API_KEY;
  const url = 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent';

  const response = await fetch(`${url}?key=${apiKey}`, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      contents: [{
        parts: [{ text }]
      }],
      generationConfig: {
        response_modalities: ['AUDIO'],
        speech_config: {
          voice_config: {
            prebuilt_voice_config: {
              voice_name: 'Puck' // ã¾ãŸã¯ 'Charon', 'Kore', 'Fenrir', 'Aoede'
            }
          }
        }
      }
    })
  });

  const data = await response.json();
  const base64Audio = data.candidates[0].content.parts[0].inline_data.data;

  // Base64ã‚’ArrayBufferã«å¤‰æ›
  const binaryString = atob(base64Audio);
  const bytes = new Uint8Array(binaryString.length);
  for (let i = 0; i < binaryString.length; i++) {
    bytes[i] = binaryString.charCodeAt(i);
  }

  return bytes.buffer;
}
```

### 2. æ•°å­—ã®èª­ã¿ä¸Šã’ï¼ˆé€šå¸¸ã‚«ã‚¦ãƒ³ãƒˆï¼‰

```typescript
/**
 * æ•°å­—ã®èª­ã¿ä¸Šã’
 */
async function speakNumber(
  num: number,
  audioContext: AudioContext
): Promise<void> {
  const text = num.toString();
  return speakTextWithLimit(text, audioContext, 0.8);
}
```

### 3. ãƒ—ãƒªã‚»ãƒƒãƒˆåŠ¹æœéŸ³ï¼ˆé‰„ç ²ã€é›»è©±ï¼‰

```typescript
/**
 * ãƒ—ãƒªã‚»ãƒƒãƒˆåŠ¹æœéŸ³ã®å†ç”Ÿ
 */
async function playPresetSound(
  soundType: 'gunshot' | 'phone',
  audioContext: AudioContext
): Promise<void> {
  // ãƒ—ãƒªã‚»ãƒƒãƒˆåŠ¹æœéŸ³ã‚’ãƒ­ãƒ¼ãƒ‰
  const audioBuffer = await loadPresetSound(soundType, audioContext);

  // å†ç”Ÿ
  const source = audioContext.createBufferSource();
  source.buffer = audioBuffer;
  source.connect(audioContext.destination);

  const startTime = audioContext.currentTime;
  source.start(startTime);

  return new Promise(resolve => {
    source.onended = () => resolve();
  });
}

/**
 * ãƒ—ãƒªã‚»ãƒƒãƒˆåŠ¹æœéŸ³ã®ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãï¼‰
 */
const presetSoundCache = new Map<string, AudioBuffer>();

async function loadPresetSound(
  soundType: 'gunshot' | 'phone',
  audioContext: AudioContext
): Promise<AudioBuffer> {
  // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
  if (presetSoundCache.has(soundType)) {
    return presetSoundCache.get(soundType)!;
  }

  // ãƒ—ãƒªã‚»ãƒƒãƒˆåŠ¹æœéŸ³ã®URLï¼ˆåŸ‹ã‚è¾¼ã¿Base64ã¾ãŸã¯CDNï¼‰
  const soundUrls = {
    gunshot: '/sounds/gunshot.mp3', // ã¾ãŸã¯ Base64 data URL
    phone: '/sounds/phone-ring.mp3',
  };

  // åŠ¹æœéŸ³ã‚’ãƒ•ã‚§ãƒƒãƒ
  const response = await fetch(soundUrls[soundType]);
  const arrayBuffer = await response.arrayBuffer();

  // ãƒ‡ã‚³ãƒ¼ãƒ‰
  const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

  // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
  presetSoundCache.set(soundType, audioBuffer);

  return audioBuffer;
}

/**
 * é›»è©±ã‚³ãƒ¼ãƒ«ã®å†ç”Ÿï¼ˆæŒ‡å®šå›æ•°ï¼‰
 */
async function playPhoneRings(
  rings: number,
  audioContext: AudioContext
): Promise<void> {
  for (let i = 0; i < rings; i++) {
    await playPresetSound('phone', audioContext);

    // ã‚³ãƒ¼ãƒ«é–“ã®é–“éš”ï¼ˆ0.3ç§’ï¼‰
    if (i < rings - 1) {
      await sleep(300);
    }
  }
}
```

### 4. ã‚«ã‚¹ã‚¿ãƒ éŸ³å£°ã®å†ç”Ÿ

```typescript
/**
 * ã‚«ã‚¹ã‚¿ãƒ éŸ³å£°ã®å†ç”Ÿï¼ˆæœ€å¾Œã¾ã§å†ç”Ÿï¼‰
 */
async function playCustomAudio(
  dataUrl: string,
  duration: number,
  audioContext: AudioContext
): Promise<void> {
  // HTML Audioè¦ç´ ã§å†ç”Ÿï¼ˆAudioContextã‚ˆã‚Šç°¡å˜ï¼‰
  return new Promise<void>((resolve, reject) => {
    const audio = new Audio(dataUrl);

    audio.onended = () => resolve();
    audio.onerror = () => reject(new Error('éŸ³å£°å†ç”Ÿã‚¨ãƒ©ãƒ¼'));

    audio.play().catch(reject);

    // å®‰å…¨ã®ãŸã‚ã€duration + 0.1ç§’ã§å¼·åˆ¶çµ‚äº†
    setTimeout(() => {
      if (!audio.ended) {
        audio.pause();
        audio.currentTime = 0;
        resolve();
      }
    }, (duration + 0.1) * 1000);
  });
}

/**
 * ã‚«ã‚¹ã‚¿ãƒ éŸ³å£°ã®å†ç”Ÿï¼ˆAudioContextç‰ˆã€ã‚ˆã‚Šæ­£ç¢ºãªã‚¿ã‚¤ãƒŸãƒ³ã‚°ï¼‰
 */
async function playCustomAudioWithContext(
  dataUrl: string,
  audioContext: AudioContext
): Promise<void> {
  // data URLã‚’ArrayBufferã«å¤‰æ›
  const arrayBuffer = await dataUrlToArrayBuffer(dataUrl);

  // ãƒ‡ã‚³ãƒ¼ãƒ‰
  const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

  // å†ç”Ÿ
  const source = audioContext.createBufferSource();
  source.buffer = audioBuffer;
  source.connect(audioContext.destination);

  const startTime = audioContext.currentTime;
  source.start(startTime);

  return new Promise(resolve => {
    source.onended = () => resolve();
  });
}

/**
 * data URLã‚’ArrayBufferã«å¤‰æ›
 */
async function dataUrlToArrayBuffer(dataUrl: string): Promise<ArrayBuffer> {
  const response = await fetch(dataUrl);
  return response.arrayBuffer();
}
```

---

## ğŸ¯ CUEéŸ³å£°ã®çµ±åˆå†ç”Ÿ

```typescript
/**
 * CUEã®éŸ³å£°ã‚’å†ç”Ÿï¼ˆéŸ³å£°ã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦åˆ†å²ï¼‰
 */
async function playCueAudio(
  cue: SmartCue,
  audioContext: AudioContext
): Promise<void> {
  switch (cue.audioType) {
    case 'number':
      // é€šå¸¸ã®ã‚«ã‚¦ãƒ³ãƒˆ
      return speakNumber(cue.timestamp, audioContext);

    case 'text':
      // ãƒ†ã‚­ã‚¹ãƒˆèª­ã¿ä¸Šã’ï¼ˆ0.8ç§’åˆ¶é™ï¼‰
      return speakTextWithLimit(cue.text || '', audioContext, 0.8);

    case 'gunshot':
      // éŠƒå£°åŠ¹æœéŸ³
      return playPresetSound('gunshot', audioContext);

    case 'phone':
      // é›»è©±ã‚³ãƒ¼ãƒ«ï¼ˆæŒ‡å®šå›æ•°ï¼‰
      return playPhoneRings(cue.phoneRings || 1, audioContext);

    case 'custom':
      // ã‚«ã‚¹ã‚¿ãƒ éŸ³å£°ï¼ˆæœ€å¾Œã¾ã§å†ç”Ÿï¼‰
      return playCustomAudio(
        cue.customAudioUrl || '',
        cue.customAudioDuration || 0,
        audioContext
      );

    default:
      console.warn('Unknown audio type:', cue.audioType);
  }
}
```

---

## â±ï¸ ã‚¿ã‚¤ãƒŸãƒ³ã‚°åˆ¶å¾¡ã®è©³ç´°

### ã‚«ã‚¦ãƒ³ãƒˆã‚¹ã‚­ãƒƒãƒ—ãƒ­ã‚¸ãƒƒã‚¯

```typescript
/**
 * ã‚«ã‚¹ã‚¿ãƒ éŸ³å£°ã®é•·ã•ã«å¿œã˜ã¦ã‚«ã‚¦ãƒ³ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—
 */
function calculateSkipCount(audioLength: number): number {
  // ä¾‹: 3.2ç§’ã®éŸ³å£° â†’ 4ã‚«ã‚¦ãƒ³ãƒˆã‚¹ã‚­ãƒƒãƒ—ï¼ˆ0, 1, 2, 3ï¼‰
  // ã¤ã¾ã‚Šã€æ¬¡ã®ã‚«ã‚¦ãƒ³ãƒˆã¯4
  return Math.ceil(audioLength);
}

/**
 * ã‚«ã‚¦ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ï¼ˆã‚¹ã‚­ãƒƒãƒ—å¯¾å¿œç‰ˆï¼‰
 */
async function runCountSequenceWithSkip(
  sequenceDuration: number,
  smartCues: SmartCue[],
  audioContext: AudioContext
): Promise<void> {
  let currentCount = 0;

  while (currentCount <= sequenceDuration) {
    const loopStartTime = audioContext.currentTime;
    const cue = smartCues.find(c => c.timestamp === currentCount);

    if (cue && cue.audioType === 'custom' && cue.customAudioDuration) {
      // ã‚«ã‚¹ã‚¿ãƒ éŸ³å£°ã‚’å†ç”Ÿ
      await playCueAudio(cue, audioContext);

      // ã‚«ã‚¦ãƒ³ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—
      const skipCount = calculateSkipCount(cue.customAudioDuration);
      currentCount += skipCount;

      // ã‚¹ã‚­ãƒƒãƒ—ã—ãŸåˆ†ã®æ™‚é–“ã¯æ—¢ã«çµŒéã—ã¦ã„ã‚‹ã®ã§ã€å¾…æ©Ÿä¸è¦
    } else if (cue && cue.audioType !== 'number') {
      // é€šå¸¸ã®CUEï¼ˆ0.8ç§’åˆ¶é™ï¼‰
      await playCueAudio(cue, audioContext);

      // 1ç§’ã¾ã§å¾…æ©Ÿ
      await waitForNextCount(loopStartTime, audioContext);
      currentCount++;
    } else {
      // é€šå¸¸ã®ã‚«ã‚¦ãƒ³ãƒˆ
      await speakNumber(currentCount, audioContext);

      // 1ç§’ã¾ã§å¾…æ©Ÿ
      await waitForNextCount(loopStartTime, audioContext);
      currentCount++;
    }
  }
}
```

### ç²¾å¯†ãªã‚¿ã‚¤ãƒŸãƒ³ã‚°åˆ¶å¾¡

```typescript
/**
 * AudioContext.currentTimeãƒ™ãƒ¼ã‚¹ã®ç²¾å¯†ãªã‚¿ã‚¤ãƒŸãƒ³ã‚°åˆ¶å¾¡
 */
class PrecisionTimer {
  private audioContext: AudioContext;
  private startTime: number = 0;

  constructor(audioContext: AudioContext) {
    this.audioContext = audioContext;
  }

  /**
   * ã‚¿ã‚¤ãƒãƒ¼é–‹å§‹
   */
  start(): void {
    this.startTime = this.audioContext.currentTime;
  }

  /**
   * çµŒéæ™‚é–“ã‚’å–å¾—ï¼ˆç§’å˜ä½ï¼‰
   */
  getElapsed(): number {
    return this.audioContext.currentTime - this.startTime;
  }

  /**
   * æ¬¡ã®ã‚«ã‚¦ãƒ³ãƒˆã¾ã§å¾…æ©Ÿ
   */
  async waitUntil(targetTime: number): Promise<void> {
    const now = this.audioContext.currentTime - this.startTime;
    const waitTime = Math.max(0, targetTime - now);

    if (waitTime > 0) {
      await sleep(waitTime * 1000);
    }
  }

  /**
   * ãƒªã‚»ãƒƒãƒˆ
   */
  reset(): void {
    this.startTime = this.audioContext.currentTime;
  }
}

/**
 * ç²¾å¯†ã‚¿ã‚¤ãƒãƒ¼ã‚’ä½¿ã£ãŸã‚«ã‚¦ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—
 */
async function runCountSequenceWithPrecisionTimer(
  sequenceDuration: number,
  smartCues: SmartCue[],
  audioContext: AudioContext
): Promise<void> {
  const timer = new PrecisionTimer(audioContext);
  timer.start();

  let currentCount = 0;

  while (currentCount <= sequenceDuration) {
    const cue = smartCues.find(c => c.timestamp === currentCount);

    // CUEå†ç”Ÿ
    if (cue && cue.audioType !== 'number') {
      await playCueAudio(cue, audioContext);

      if (cue.audioType === 'custom' && cue.customAudioDuration) {
        // ã‚«ã‚¹ã‚¿ãƒ éŸ³å£°ã®é•·ã•ã ã‘ã‚¹ã‚­ãƒƒãƒ—
        const skipCount = calculateSkipCount(cue.customAudioDuration);
        currentCount += skipCount;

        // æ¬¡ã®ã‚«ã‚¦ãƒ³ãƒˆã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã¾ã§å¾…æ©Ÿ
        await timer.waitUntil(currentCount);
      } else {
        // æ¬¡ã®ã‚«ã‚¦ãƒ³ãƒˆï¼ˆ1ç§’å¾Œï¼‰ã¾ã§å¾…æ©Ÿ
        currentCount++;
        await timer.waitUntil(currentCount);
      }
    } else {
      // é€šå¸¸ã®ã‚«ã‚¦ãƒ³ãƒˆ
      await speakNumber(currentCount, audioContext);

      // æ¬¡ã®ã‚«ã‚¦ãƒ³ãƒˆï¼ˆ1ç§’å¾Œï¼‰ã¾ã§å¾…æ©Ÿ
      currentCount++;
      await timer.waitUntil(currentCount);
    }
  }
}
```

---

## ğŸ”‡ ãƒŸãƒ¥ãƒ¼ãƒˆæ©Ÿèƒ½ã¨ã®çµ±åˆ

```typescript
/**
 * ãƒŸãƒ¥ãƒ¼ãƒˆçŠ¶æ…‹ã‚’è€ƒæ…®ã—ãŸCUEå†ç”Ÿ
 */
async function playCueAudioWithMute(
  cue: SmartCue,
  audioContext: AudioContext,
  isMuted: boolean
): Promise<void> {
  if (isMuted) {
    // ãƒŸãƒ¥ãƒ¼ãƒˆæ™‚ã¯éŸ³å£°ã‚’å†ç”Ÿã›ãšã€å¾…æ©Ÿã®ã¿
    if (cue.audioType === 'custom' && cue.customAudioDuration) {
      // ã‚«ã‚¹ã‚¿ãƒ éŸ³å£°ã®é•·ã•ã ã‘å¾…æ©Ÿ
      await sleep(cue.customAudioDuration * 1000);
    } else {
      // 0.8ç§’å¾…æ©Ÿï¼ˆé€šå¸¸ã®CUEï¼‰
      await sleep(800);
    }
  } else {
    // é€šå¸¸ã®å†ç”Ÿ
    await playCueAudio(cue, audioContext);
  }
}
```

---

## ğŸšï¸ ãƒœãƒªãƒ¥ãƒ¼ãƒ åˆ¶å¾¡

```typescript
/**
 * ãƒœãƒªãƒ¥ãƒ¼ãƒ ä»˜ãéŸ³å£°å†ç”Ÿ
 */
async function playAudioWithVolume(
  audioBuffer: AudioBuffer,
  audioContext: AudioContext,
  volume: number = 1.0
): Promise<void> {
  // GainNodeã§ãƒœãƒªãƒ¥ãƒ¼ãƒ åˆ¶å¾¡
  const gainNode = audioContext.createGain();
  gainNode.gain.value = volume;

  const source = audioContext.createBufferSource();
  source.buffer = audioBuffer;
  source.connect(gainNode);
  gainNode.connect(audioContext.destination);

  const startTime = audioContext.currentTime;
  source.start(startTime);

  return new Promise(resolve => {
    source.onended = () => resolve();
  });
}

/**
 * ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¤ãƒ³/ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¢ã‚¦ãƒˆ
 */
async function playAudioWithFade(
  audioBuffer: AudioBuffer,
  audioContext: AudioContext,
  fadeInDuration: number = 0.1,
  fadeOutDuration: number = 0.1
): Promise<void> {
  const gainNode = audioContext.createGain();

  const source = audioContext.createBufferSource();
  source.buffer = audioBuffer;
  source.connect(gainNode);
  gainNode.connect(audioContext.destination);

  const startTime = audioContext.currentTime;
  const duration = audioBuffer.duration;

  // ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¤ãƒ³
  gainNode.gain.setValueAtTime(0, startTime);
  gainNode.gain.linearRampToValueAtTime(1, startTime + fadeInDuration);

  // ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¢ã‚¦ãƒˆ
  gainNode.gain.setValueAtTime(1, startTime + duration - fadeOutDuration);
  gainNode.gain.linearRampToValueAtTime(0, startTime + duration);

  source.start(startTime);

  return new Promise(resolve => {
    source.onended = () => resolve();
  });
}
```

---

## ğŸ¤ éŸ³å£°å“è³ªã®æœ€é©åŒ–

### 1. ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®è¨­å®š

```typescript
/**
 * æœ€é©ãªAudioContextã®ä½œæˆ
 */
function createOptimizedAudioContext(): AudioContext {
  const audioContext = new AudioContext({
    latencyHint: 'interactive', // ä½ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼
    sampleRate: 44100, // CDå“è³ª
  });

  return audioContext;
}
```

### 2. ãƒ—ãƒªãƒ­ãƒ¼ãƒ‰ï¼†ã‚­ãƒ£ãƒƒã‚·ãƒ¥

```typescript
/**
 * SMART CUESã®éŸ³å£°ã‚’äº‹å‰ã«ãƒ—ãƒªãƒ­ãƒ¼ãƒ‰
 */
async function preloadSmartCuesAudio(
  smartCues: SmartCue[],
  audioContext: AudioContext
): Promise<void> {
  const promises = smartCues.map(async cue => {
    switch (cue.audioType) {
      case 'text':
        // ãƒ†ã‚­ã‚¹ãƒˆã®TTSã‚’äº‹å‰ç”Ÿæˆ
        if (cue.text) {
          const audioData = await generateTTS(cue.text);
          const audioBuffer = await audioContext.decodeAudioData(audioData);
          // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
          ttsCache.set(cue.text, audioBuffer);
        }
        break;

      case 'gunshot':
      case 'phone':
        // ãƒ—ãƒªã‚»ãƒƒãƒˆåŠ¹æœéŸ³ã‚’ãƒ—ãƒªãƒ­ãƒ¼ãƒ‰
        await loadPresetSound(cue.audioType, audioContext);
        break;

      case 'custom':
        // ã‚«ã‚¹ã‚¿ãƒ éŸ³å£°ã‚’ãƒ—ãƒªãƒ­ãƒ¼ãƒ‰
        if (cue.customAudioUrl) {
          const arrayBuffer = await dataUrlToArrayBuffer(cue.customAudioUrl);
          const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
          customAudioCache.set(cue.id, audioBuffer);
        }
        break;
    }
  });

  await Promise.all(promises);
}

// ã‚­ãƒ£ãƒƒã‚·ãƒ¥
const ttsCache = new Map<string, AudioBuffer>();
const customAudioCache = new Map<string, AudioBuffer>();
```

---

## ğŸ§ª ãƒ†ã‚¹ãƒˆã¨ãƒ‡ãƒãƒƒã‚°

### ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°

```typescript
/**
 * éŸ³å£°å†ç”Ÿã®ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°
 */
function logAudioPlayback(
  cue: SmartCue,
  startTime: number,
  endTime: number
): void {
  console.log('[Audio Playback]', {
    timestamp: cue.timestamp,
    audioType: cue.audioType,
    startTime,
    endTime,
    duration: endTime - startTime,
    text: cue.text,
  });
}

/**
 * ã‚«ã‚¦ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã®ãƒ‡ãƒãƒƒã‚°ç‰ˆ
 */
async function runCountSequenceDebug(
  sequenceDuration: number,
  smartCues: SmartCue[],
  audioContext: AudioContext
): Promise<void> {
  let currentCount = 0;

  while (currentCount <= sequenceDuration) {
    const loopStartTime = audioContext.currentTime;
    const cue = smartCues.find(c => c.timestamp === currentCount);

    console.log(`[Count ${currentCount}]`, {
      hasCue: !!cue,
      audioType: cue?.audioType,
      currentTime: audioContext.currentTime,
    });

    if (cue && cue.audioType !== 'number') {
      await playCueAudio(cue, audioContext);
      const loopEndTime = audioContext.currentTime;
      logAudioPlayback(cue, loopStartTime, loopEndTime);

      if (cue.audioType === 'custom' && cue.customAudioDuration) {
        const skipCount = calculateSkipCount(cue.customAudioDuration);
        console.log(`[Skip] Skipping ${skipCount} counts`);
        currentCount += skipCount;
      } else {
        await waitForNextCount(loopStartTime, audioContext);
        currentCount++;
      }
    } else {
      await speakNumber(currentCount, audioContext);
      await waitForNextCount(loopStartTime, audioContext);
      currentCount++;
    }
  }
}
```

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ

```typescript
/**
 * éŸ³å£°å†ç”Ÿã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®š
 */
async function measureAudioPerformance(
  cue: SmartCue,
  audioContext: AudioContext
): Promise<number> {
  const startTime = performance.now();
  await playCueAudio(cue, audioContext);
  const endTime = performance.now();

  const elapsed = endTime - startTime;
  console.log(`[Performance] ${cue.audioType} took ${elapsed.toFixed(2)}ms`);

  return elapsed;
}
```

---

## ğŸ“Š éŸ³å£°ã‚¨ãƒ³ã‚¸ãƒ³ã®çŠ¶æ…‹ç®¡ç†

```typescript
/**
 * éŸ³å£°ã‚¨ãƒ³ã‚¸ãƒ³ã®çŠ¶æ…‹
 */
interface AudioEngineState {
  isPlaying: boolean;
  currentCount: number;
  audioContext: AudioContext | null;
  isPaused: boolean;
  isMuted: boolean;
  volume: number;
}

/**
 * éŸ³å£°ã‚¨ãƒ³ã‚¸ãƒ³ã‚¯ãƒ©ã‚¹
 */
class SmartCuesAudioEngine {
  private state: AudioEngineState;
  private smartCues: SmartCue[];

  constructor(smartCues: SmartCue[]) {
    this.smartCues = smartCues;
    this.state = {
      isPlaying: false,
      currentCount: 0,
      audioContext: null,
      isPaused: false,
      isMuted: false,
      volume: 1.0,
    };
  }

  /**
   * åˆæœŸåŒ–
   */
  async initialize(): Promise<void> {
    this.state.audioContext = createOptimizedAudioContext();
    await preloadSmartCuesAudio(this.smartCues, this.state.audioContext);
  }

  /**
   * å†ç”Ÿé–‹å§‹
   */
  async play(sequenceDuration: number): Promise<void> {
    if (!this.state.audioContext) {
      throw new Error('AudioContext not initialized');
    }

    this.state.isPlaying = true;
    this.state.currentCount = 0;

    await runCountSequenceWithPrecisionTimer(
      sequenceDuration,
      this.smartCues,
      this.state.audioContext
    );

    this.state.isPlaying = false;
  }

  /**
   * ä¸€æ™‚åœæ­¢
   */
  pause(): void {
    this.state.isPaused = true;
    this.state.audioContext?.suspend();
  }

  /**
   * å†é–‹
   */
  resume(): void {
    this.state.isPaused = false;
    this.state.audioContext?.resume();
  }

  /**
   * åœæ­¢
   */
  stop(): void {
    this.state.isPlaying = false;
    this.state.currentCount = 0;
  }

  /**
   * ãƒŸãƒ¥ãƒ¼ãƒˆåˆ‡ã‚Šæ›¿ãˆ
   */
  toggleMute(): void {
    this.state.isMuted = !this.state.isMuted;
  }

  /**
   * ãƒœãƒªãƒ¥ãƒ¼ãƒ è¨­å®š
   */
  setVolume(volume: number): void {
    this.state.volume = Math.max(0, Math.min(1, volume));
  }

  /**
   * ç¾åœ¨ã®çŠ¶æ…‹ã‚’å–å¾—
   */
  getState(): AudioEngineState {
    return { ...this.state };
  }
}
```

---

**ä½œæˆæ—¥**: 2025-01-12
**æœ€çµ‚æ›´æ–°**: 2025-01-12
**ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: è¨­è¨ˆå®Œäº†ã€å®Ÿè£…å¾…ã¡
